{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10409147,"sourceType":"datasetVersion","datasetId":6450551},{"sourceId":10549491,"sourceType":"datasetVersion","datasetId":6527299},{"sourceId":12431403,"sourceType":"datasetVersion","datasetId":7841431},{"sourceId":12431421,"sourceType":"datasetVersion","datasetId":7841445},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":3900,"modelId":1902}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/adityabhaskar12/rag-originbluy?scriptVersionId=249919557\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Package Installation**\nInstalls all necessary Python dependencies for the RAG system:\n- **OCR/Image Processing**: opencv-python, pdf2image, Pillow, EasyOCR\n- **Document Parsing**: PyMuPDF (PDFs), python-docx (Word), mammoth\n- **ML/NLP**: transformers, sentence-transformers, torch\n- **Vector DB**: chromadb\n- **Utils**: numpy, langchain-community","metadata":{}},{"cell_type":"code","source":"!pip install opencv-python\n!pip install PyMuPDF\n!pip install transformers\n!pip install torch\n!pip install numpy\n!pip install sentence-transformers\n!pip install pdf2image\n!pip install python-docx\n!pip install mammoth\n!pip install chromadb\n!pip install Pillow\n!pip install git+https://github.com/JaidedAI/EasyOCR.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:08:09.216226Z","iopub.execute_input":"2025-07-11T07:08:09.216473Z","iopub.status.idle":"2025-07-11T07:11:13.01399Z","shell.execute_reply.started":"2025-07-11T07:08:09.216453Z","shell.execute_reply":"2025-07-11T07:11:13.013304Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nCollecting PyMuPDF\n  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDF\nSuccessfully installed PyMuPDF-1.26.3\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.2.1)\nCollecting python-docx\n  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\nRequirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\nDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: python-docx\nSuccessfully installed python-docx-1.2.0\nCollecting mammoth\n  Downloading mammoth-1.9.1-py2.py3-none-any.whl.metadata (24 kB)\nCollecting cobble<0.2,>=0.1.3 (from mammoth)\n  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\nDownloading mammoth-1.9.1-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\nInstalling collected packages: cobble, mammoth\nSuccessfully installed cobble-0.1.4 mammoth-1.9.1\nCollecting chromadb\n  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.33.1)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=e0b6944b8b8221a1b2db2cc44e0325b34deba98d5e42e4ff1578237c121b9071\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, python-dotenv, pybase64, protobuf, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, onnxruntime, chromadb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.1.0 onnxruntime-1.22.1 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 posthog-5.4.0 protobuf-5.29.5 pybase64-1.4.1 pypika-0.48.9 python-dotenv-1.1.1 uvloop-0.21.0 watchfiles-1.1.0\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\nCollecting git+https://github.com/JaidedAI/EasyOCR.git\n  Cloning https://github.com/JaidedAI/EasyOCR.git to /tmp/pip-req-build-a2onn2ot\n  Running command git clone --filter=blob:none --quiet https://github.com/JaidedAI/EasyOCR.git /tmp/pip-req-build-a2onn2ot\n  Resolved https://github.com/JaidedAI/EasyOCR.git to commit c4f3cd7225efd4f85451bd8b4a7646ae9a092420\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (0.21.0+cu124)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (4.11.0.86)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (1.15.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (11.2.1)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (0.25.2)\nRequirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (0.6.6)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (6.0.2)\nRequirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (2.1.1)\nRequirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (1.3.0.post6)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr==1.7.2) (1.11.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr==1.7.2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr==1.7.2) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->easyocr==1.7.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->easyocr==1.7.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->easyocr==1.7.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->easyocr==1.7.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->easyocr==1.7.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->easyocr==1.7.2) (2.4.1)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr==1.7.2) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr==1.7.2) (2025.6.11)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr==1.7.2) (25.0)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr==1.7.2) (0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr==1.7.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->easyocr==1.7.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->easyocr==1.7.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->easyocr==1.7.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->easyocr==1.7.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->easyocr==1.7.2) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## System Configuration\nInstalls essential system libraries:\n- `poppler-utils`: PDF rendering\n- `tesseract-ocr`: OCR engine\n- `libgl1`: OpenGL support for GUI-less environments","metadata":{}},{"cell_type":"code","source":"!sudo apt update\n!sudo apt install -y poppler-utils tesseract-ocr libgl1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:11:47.463374Z","iopub.execute_input":"2025-07-11T07:11:47.463628Z","iopub.status.idle":"2025-07-11T07:12:00.544862Z","shell.execute_reply.started":"2025-07-11T07:11:47.463606Z","shell.execute_reply":"2025-07-11T07:12:00.544167Z"}},"outputs":[{"name":"stdout","text":"Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B][33m\nGet:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \u001b[0m\nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,804 kB]\nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                         \u001b[0m\nGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \u001b[0m\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \u001b[0m\u001b[33m\nGet:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,092 kB]  \u001b[0m\u001b[33m\u001b[33m\u001b[33m\nGet:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]3m\nGet:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,757 kB][0m\u001b[33m\nGet:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \u001b[0m\nGet:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,795 kB]\nHit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \u001b[0m\u001b[33m\nGet:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,569 kB]\nGet:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [51.0 kB]\nGet:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]3m\u001b[33m\u001b[33m\nGet:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,266 kB]\nGet:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,103 kB]3m\nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,420 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,963 kB]33m\nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [56.4 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\nFetched 33.5 MB in 2s (13.5 MB/s)[33m[33m\u001b[33m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\n70 packages can be upgraded. Run 'apt list --upgradable' to see them.\n\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nlibgl1 is already the newest version (1.4.0-1).\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\nThe following NEW packages will be installed:\n  poppler-utils\n0 upgraded, 1 newly installed, 0 to remove and 70 not upgraded.\nNeed to get 186 kB of archives.\nAfter this operation, 697 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\nFetched 186 kB in 1s (283 kB/s)       \u001b[0m\u001b[33m\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\ndebconf: falling back to frontend: Readline\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package poppler-utils.\n(Reading database ... 128663 files and directories currently installed.)\nPreparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.10.2-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 🔄 LangChain Update\nUpgrades `langchain-community` to ensure compatibility with the latest document processing features.","metadata":{}},{"cell_type":"code","source":"!pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:12:06.06345Z","iopub.execute_input":"2025-07-11T07:12:06.064126Z","iopub.status.idle":"2025-07-11T07:12:12.033161Z","shell.execute_reply.started":"2025-07-11T07:12:06.064085Z","shell.execute_reply":"2025-07-11T07:12:12.032367Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.66)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain-community)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, httpx-sse, pydantic-settings, langchain-community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed httpx-sse-0.4.1 langchain-community-0.3.27 packaging-24.2 pydantic-settings-2.10.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 🤗 HuggingFace Setup\nInstalls LangChain-HuggingFace integration for:\n- Seamless transformer model usage\n- Pipeline management\n- Optimized LLM inference","metadata":{}},{"cell_type":"code","source":"!pip install -U langchain-huggingface transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:12:13.285171Z","iopub.execute_input":"2025-07-11T07:12:13.286059Z","iopub.status.idle":"2025-07-11T07:12:26.799272Z","shell.execute_reply.started":"2025-07-11T07:12:13.286028Z","shell.execute_reply":"2025-07-11T07:12:26.798492Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-huggingface\n  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nCollecting transformers\n  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.66)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.2)\nRequirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.5)\nRequirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.7)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.16.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\nDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\nDownloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-huggingface, transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\nSuccessfully installed langchain-huggingface-0.3.0 transformers-4.53.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"##  Import Dependencies\nKey imports organized by functionality:\n\n### **Document Processing**\n- `fitz` (PyMuPDF), `Document` (docx), `pdf2image`\n- `easyocr` for OCR\n\n### **NLP/ML**\n- HuggingFace `transformers`, `pipeline`\n- `TableTransformerForObjectDetection` (table extraction)\n\n### **Vector DB**\n- `Chroma` vector store\n- `HuggingFaceEmbeddings`\n\n### **Utils**\n- `RecursiveCharacterTextSplitter` for chunking\n- `PromptTemplate` for LLM instructions","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport cv2\nimport fitz \nfrom docx import Document\nfrom typing import List, Dict, Any, Optional\nfrom pdf2image import convert_from_path\nimport easyocr\nimport torch\nfrom langchain_huggingface import HuggingFaceEmbeddings \nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_core.documents import Document as LangchainDocument\nfrom langchain.prompts import PromptTemplate\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    pipeline,\n    TableTransformerForObjectDetection,\n    DetrImageProcessor\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:12:27.223935Z","iopub.execute_input":"2025-07-11T07:12:27.22464Z","iopub.status.idle":"2025-07-11T07:13:01.310619Z","shell.execute_reply.started":"2025-07-11T07:12:27.224611Z","shell.execute_reply":"2025-07-11T07:13:01.310058Z"}},"outputs":[{"name":"stderr","text":"2025-07-11 07:12:43.583152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752217963.912539      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752217964.003074      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## System Configuration\nCentralized settings via `Config` class:\n\n    CHROMA_DIR = \"chroma_db\"  # Vector storage\n    \n    MISTRAL_PATH = \"/kaggle/input/mistral/...\"  # LLM path  \n    \n    EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  \n    \n    SUPPORTED_EXTS = {'.pdf', '.docx', '.txt'}  # File types\n    \n    MAX_DOC_SIZE = 100MB  # Total file size limit\n    \n    DEVICE = \"cuda\" if available else \"cpu\"  # Hardware acceleration \n                                             # if nvidia gpu is provided uses that else uses cpu","metadata":{}},{"cell_type":"code","source":"class Config:\n    CHROMA_DIR = \"chroma_db\"\n    MISTRAL_PATH = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n    SUPPORTED_EXTS = {'.pdf', '.docx', '.txt'}\n    MAX_DOC_SIZE = 100 * 1024 * 1024  \n    MAX_DOCUMENTS = 10\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:09.406191Z","iopub.execute_input":"2025-07-11T07:13:09.406471Z","iopub.status.idle":"2025-07-11T07:13:09.411156Z","shell.execute_reply.started":"2025-07-11T07:13:09.40645Z","shell.execute_reply":"2025-07-11T07:13:09.410519Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"##  Document Processor\nAdvanced multi-format parser with:\n\n### Key Features:\n1. **PDF Processing**\n   - OCR with EasyOCR\n   - Table detection (Table Transformer)\n   - Fallback to PyMuPDF text extraction\n\n2. **DOCX Support**\n   - Paragraph extraction\n   - Table content preservation\n\n3. **TXT FILE Support**","metadata":{"execution":{"iopub.status.busy":"2025-07-10T16:20:52.925276Z","iopub.execute_input":"2025-07-10T16:20:52.925565Z","iopub.status.idle":"2025-07-10T16:20:52.936465Z","shell.execute_reply.started":"2025-07-10T16:20:52.92554Z","shell.execute_reply":"2025-07-10T16:20:52.934965Z"}}},{"cell_type":"code","source":"class DocumentProcessor:\n    def __init__(self):\n        try:\n            self.ocr_reader = easyocr.Reader(['en'])\n            self.table_processor = DetrImageProcessor.from_pretrained(\n               \"microsoft/table-transformer-detection\",\n                size={\"longest_edge\": 1000}, \n                use_fast=True\n            )\n            self.table_detector = TableTransformerForObjectDetection.from_pretrained(\n                \"microsoft/table-transformer-detection\"\n            ).to(Config.DEVICE)\n        except Exception as e:\n            print(f\"Initialization error: {str(e)}\")\n            raise\n\n    def process_file(self, file_path: str) -> List[Dict[str, Any]]:\n        \"\"\"Main method to process any supported file type\"\"\"\n        ext = os.path.splitext(file_path)[1].lower()\n        try:\n            if ext == '.pdf':\n                return self._process_pdf(file_path)\n            elif ext == '.docx':\n                return self._process_docx(file_path)\n            elif ext == '.txt':\n                return self._process_txt(file_path)\n        except Exception as e:\n            print(f\"Error processing {file_path}: {str(e)}\")\n            return []\n\n    def _process_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:\n        \"\"\"Process PDF with OCR and table detection, with robust fallback\"\"\"\n        try:\n            advanced_result = self._process_pdf_with_ocr_and_tables(pdf_path)\n            if advanced_result:\n                return advanced_result\n        except Exception as e:\n            print(f\"Advanced processing failed: {str(e)}\")\n        try:\n            doc = fitz.open(pdf_path)\n            return [{\n                \"page_number\": i + 1,\n                \"content\": [{\"type\": \"text\", \"content\": page.get_text()}],\n                \"source\": os.path.basename(pdf_path)\n            } for i, page in enumerate(doc)]\n        except Exception as e:\n            print(f\"Simple PDF processing failed: {str(e)}\")\n            return []\n\n    def _process_pdf_with_ocr_and_tables(self, pdf_path: str) -> List[Dict[str, Any]]:\n        \"\"\"Advanced PDF processing with OCR and table detection\"\"\"\n        try:\n            images = convert_from_path(pdf_path)\n            doc = fitz.open(pdf_path)\n            extracted_data = []\n\n            for page_num, (image, page) in enumerate(zip(images, doc), 1):\n                page_content = []\n                cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n\n                # TABLE DETECTION (only if GPU available)\n                table_boxes = []\n                if torch.cuda.is_available():\n                    try:\n                        inputs = self.table_processor(images=image, return_tensors=\"pt\").to(Config.DEVICE)\n                        with torch.no_grad():\n                            outputs = self.table_detector(**inputs)\n\n                        target_sizes = torch.tensor([image.size[::-1]])\n                        results = self.table_processor.post_process_object_detection(\n                            outputs, threshold=0.9, target_sizes=target_sizes\n                        )[0]\n\n                        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n                            if score > 0.9 and label == self.table_detector.config.id2label[1]:\n                                box = [int(i) for i in box.tolist()]\n                                table_boxes.append((box[1], box[0], box[3], box[2]))\n                    except Exception as e:\n                        print(f\"Table detection failed, continuing without tables: {str(e)}\")\n                try:\n                    if table_boxes:\n                        mask = np.ones(cv_image.shape[:2], dtype=np.uint8) * 255\n                        for y0, x0, y1, x1 in table_boxes:\n                            cv2.rectangle(mask, (x0, y0), (x1, y1), 0, -1)\n                        masked_image = cv2.bitwise_and(cv_image, cv_image, mask=mask)\n                    else:\n                        masked_image = cv_image\n                    ocr_results = self.ocr_reader.readtext(masked_image, paragraph=True)\n                    for result in ocr_results:\n                        try:\n                            if len(result) >= 2:\n                                text = result[1]\n                                bbox = result[0]\n                                page_content.append({\n                                    \"type\": \"text\",\n                                    \"content\": text,\n                                    \"position\": [int(coord) for point in bbox for coord in point] if bbox else []\n                                })\n                        except Exception as e:\n                            print(f\"Error processing OCR result: {str(e)}\")\n\n                except Exception as e:\n                    print(f\"OCR failed for page {page_num}, falling back to simple text: {str(e)}\")\n                    page_content.append({\n                        \"type\": \"text\",\n                        \"content\": page.get_text(),\n                        \"position\": []\n                    })\n                for y0, x0, y1, x1 in table_boxes:\n                    try:\n                        table_img = cv_image[y0:y1, x0:x1]\n                        table_results = self.ocr_reader.readtext(table_img)\n                        table_content = [res[1] for res in table_results if len(res) >= 2]\n\n                        page_content.append({\n                            \"type\": \"table\",\n                            \"content\": table_content,\n                            \"position\": [x0, y0, x1, y1]\n                        })\n                    except Exception as e:\n                        print(f\"Table processing failed: {str(e)}\")\n\n                extracted_data.append({\n                    \"page_number\": page_num,\n                    \"content\": page_content,\n                    \"source\": os.path.basename(pdf_path)\n                })\n\n            return extracted_data\n\n        except Exception as e:\n            raise Exception(f\"PDF processing failed: {str(e)}\")\n\n    def _process_docx(self, docx_path: str) -> List[Dict[str, Any]]:\n        \"\"\"Process DOCX files with table support\"\"\"\n        try:\n            doc = Document(docx_path)\n            content = []\n            for para in doc.paragraphs:\n                if para.text.strip():\n                    content.append({\n                        \"type\": \"text\",\n                        \"content\": para.text\n                    })\n            for table in doc.tables:\n                table_data = []\n                for row in table.rows:\n                    row_data = [cell.text for cell in row.cells]\n                    table_data.append(row_data)\n                content.append({\n                    \"type\": \"table\",\n                    \"content\": table_data\n                })\n\n            return [{\n                \"page_number\": 1,\n                \"content\": content,\n                \"source\": os.path.basename(docx_path)\n            }]\n        except Exception as e:\n            print(f\"DOCX processing error: {str(e)}\")\n            return []\n\n    def _process_txt(self, txt_path: str) -> List[Dict[str, Any]]:\n        \"\"\"Process plain text files\"\"\"\n        try:\n            with open(txt_path, 'r', encoding='utf-8') as f:\n                return [{\n                    \"page_number\": 1,\n                    \"content\": [{\"type\": \"text\", \"content\": f.read()}],\n                    \"source\": os.path.basename(txt_path)\n                }]\n        except Exception as e:\n            print(f\"TXT processing error: {str(e)}\")\n            return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:13.968327Z","iopub.execute_input":"2025-07-11T07:13:13.968601Z","iopub.status.idle":"2025-07-11T07:13:13.988314Z","shell.execute_reply.started":"2025-07-11T07:13:13.968581Z","shell.execute_reply":"2025-07-11T07:13:13.987776Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"##  Vector Database Setup\nCreates search-optimized document storage:\n","metadata":{}},{"cell_type":"code","source":"class VectorStoreManager:\n    def __init__(self):\n        self.embedding_model = HuggingFaceEmbeddings(\n            model_name=Config.EMBEDDING_MODEL,\n            model_kwargs={'device': Config.DEVICE}\n        )\n        self.text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=1000,\n            chunk_overlap=200\n        )\n\n    def create_store(self, documents: List[Dict]) -> Optional[Chroma]:\n        if not documents:\n            return None\n\n        lc_docs = []\n        for doc in documents:\n            for content in doc['content']:\n                if content['type'] == 'text':\n                    for chunk in self.text_splitter.split_text(content['content']):\n                        lc_docs.append(LangchainDocument(\n                            page_content=chunk,\n                            metadata={} \n                        ))\n                elif content['type'] == 'table':\n                    table_text = \" | \".join([\" | \".join(row) for row in content['content']])\n                    lc_docs.append(LangchainDocument(\n                        page_content=f\"TABLE: {table_text}\",\n                        metadata={}\n                    ))\n\n        return Chroma.from_documents(\n            documents=lc_docs,\n            embedding=self.embedding_model,\n            persist_directory=Config.CHROMA_DIR\n        ) if lc_docs else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:20.865703Z","iopub.execute_input":"2025-07-11T07:13:20.866233Z","iopub.status.idle":"2025-07-11T07:13:20.872265Z","shell.execute_reply.started":"2025-07-11T07:13:20.866207Z","shell.execute_reply":"2025-07-11T07:13:20.871637Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## LLM Initialization\n```markdown\nMistral-7B LLM Wrapper","metadata":{}},{"cell_type":"code","source":"class MistralLLM:\n    def __init__(self):\n        try:\n            from langchain_community.llms import HuggingFacePipeline  # Correct import\n            \n            self.tokenizer = AutoTokenizer.from_pretrained(Config.MISTRAL_PATH)\n            self.model = AutoModelForCausalLM.from_pretrained(\n                Config.MISTRAL_PATH,\n                torch_dtype=torch.float16,\n                device_map=\"auto\"\n            )\n            self.pipe = pipeline(\n                \"text-generation\",\n                model=self.model,\n                tokenizer=self.tokenizer,\n                max_new_tokens=512,\n                temperature=0.1,\n                device_map=\"auto\"\n            )\n            self.llm = HuggingFacePipeline(pipeline=self.pipe)\n        except Exception as e:\n            print(f\"LLM initialization failed: {str(e)}\")\n            self.llm = None\n\n    def query(self, vectordb: Chroma, query: str, k: int = 3) -> str:\n        if not self.llm:\n            return \"LLM not initialized\"\n            \n        retriever = vectordb.as_retriever(search_kwargs={\"k\": k})\n        qa = RetrievalQA.from_chain_type(\n            llm=self.llm,\n            chain_type=\"stuff\",\n            retriever=retriever,\n            return_source_documents=True\n        )\n        result = qa({\"query\": query})\n        return f\"Answer: {result['result']}\\nSources: {[d.metadata['source'] for d in result['source_documents']]}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:25.578498Z","iopub.execute_input":"2025-07-11T07:13:25.578775Z","iopub.status.idle":"2025-07-11T07:13:25.585156Z","shell.execute_reply.started":"2025-07-11T07:13:25.578752Z","shell.execute_reply":"2025-07-11T07:13:25.584526Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Prompt Template\nStructured prompt enforcing:\n- Source synthesis\n- Conflict resolution\n- Bullet-point formatting","metadata":{}},{"cell_type":"code","source":"RAG_PROMPT_TEMPLATE = \"\"\"As an expert document analyst with access to multiple sources, your task is to provide the most accurate, well-structured answer to the user's question:\n\n1. Context Analysis:\n{context}\n\n2. Question:\n{question}\n\n3. Answer Generation Rules:\n- Synthesize information from all relevant context\n- Acknowledge when information is incomplete\n- Break down complex answers into bullet points when helpful\n- Highlight key statistics, names, and dates\n- If conflicting information exists, present both sides with sources\n- For technical queries, provide detailed explanations\n- For summary requests, include all major points\n\n4. Required Answer Format:\n[Start of Answer]\n### Comprehensive Response:\n[Your synthesized answer here]\nonly include relevant sources\n[End of Answer]\"\"\"\nrag_prompt = PromptTemplate(\n    template=RAG_PROMPT_TEMPLATE,\n    input_variables=[\"context\", \"question\"]\n)\ndef create_qa_chain(llm, vectordb, k=3):\n    return RetrievalQA.from_chain_type(\n        llm=llm,\n        chain_type=\"stuff\",\n        retriever=vectordb.as_retriever(search_kwargs={\"k\": k}),\n        return_source_documents=True,  \n        chain_type_kwargs={\n            \"prompt\": rag_prompt, \n            \"document_prompt\": PromptTemplate(\n                input_variables=[\"page_content\"],\n                template=\"{page_content}\" \n            )\n        }\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:31.533665Z","iopub.execute_input":"2025-07-11T07:13:31.534321Z","iopub.status.idle":"2025-07-11T07:13:31.538859Z","shell.execute_reply.started":"2025-07-11T07:13:31.534297Z","shell.execute_reply":"2025-07-11T07:13:31.538353Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Enhanced Query Handling\nExtends base LLM with:\n- Custom retrieval-augmented generation\n- Error handling\n- Simplified response format","metadata":{}},{"cell_type":"code","source":"class ExtendedMistralLLM(MistralLLM):\n    def query(self, vectordb: Chroma, query: str, k: int = 3) -> str:\n        if not self.llm:\n            return \"LLM not initialized\"\n            \n        qa_chain = create_qa_chain(self.llm, vectordb, k)\n        try:\n            result = qa_chain.invoke({\"query\": query})\n            return result[\"result\"]\n        except Exception as e:\n            return f\"Error processing query: {str(e)}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:36.402211Z","iopub.execute_input":"2025-07-11T07:13:36.402807Z","iopub.status.idle":"2025-07-11T07:13:36.407053Z","shell.execute_reply.started":"2025-07-11T07:13:36.402784Z","shell.execute_reply":"2025-07-11T07:13:36.406502Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Execution Pipeline\nEnd-to-end document processing flow:\n\n1. **Input:** List of document paths\n2. **Processing:**\n   - Size validation\n   - Parallel parsing\n3. **Query Loop:**\n   - Interactive question answering","metadata":{}},{"cell_type":"code","source":"def main():\n    processor = DocumentProcessor()\n    vs_manager = VectorStoreManager()\n    llm = ExtendedMistralLLM()\n\n    document_paths = [\n        \"/kaggle/input/daafile/End Sem DAA.pdf\",\n        \"/kaggle/input/txtfile/SampleTextFile_1000kb.txt\",\n        \"/kaggle/input/womensafetycasestudy/Women Safety_v3.pdf\",\n        \"/kaggle/input/wordfile/uhvprojectcopy.docx\",\n    ][:Config.MAX_DOCUMENTS]\n\n    all_docs = []\n    for path in document_paths:\n        if os.path.getsize(path) > Config.MAX_DOC_SIZE:\n            print(f\"Skipping {path} - exceeds size limit\")\n            continue\n            \n        docs = processor.process_file(path)\n        if docs:\n            all_docs.extend(docs)\n            print(f\"Processed {path}\")\n        else:\n            print(f\"Failed to process {path}\")\n\n    if all_docs:\n        vectordb = vs_manager.create_store(all_docs)\n        if vectordb:\n            print(\"Vector store created\")\n            while True:\n                query = input(\"\\nEnter question (or 'exit'): \")\n                if query.lower() == 'exit':\n                    break\n                print(llm.query(vectordb, query))\n        else:\n            print(\"Failed to create vector store\")\n    else:\n        print(\"No documents processed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:41.313666Z","iopub.execute_input":"2025-07-11T07:13:41.314378Z","iopub.status.idle":"2025-07-11T07:13:41.319911Z","shell.execute_reply.started":"2025-07-11T07:13:41.31435Z","shell.execute_reply":"2025-07-11T07:13:41.319162Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Memory Optimization\nProactive resource cleanup","metadata":{}},{"cell_type":"code","source":"import torch\nimport gc\nfrom IPython.display import clear_output\n\ndef clear_memory():\n    \"\"\"Comprehensive memory cleanup for Kaggle notebooks\"\"\"\n    try:\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n            print(\"Cleared CUDA cache\")\n        gc.collect()\n        print(\"Ran garbage collection\")\n        clear_output(wait=True)\n        if torch.cuda.is_available():\n            print(f\"Current GPU memory usage: {torch.cuda.memory_allocated()/1024**2:.2f}MB / {torch.cuda.memory_reserved()/1024**2:.2f}MB\")\n        else:\n            print(\"Memory cleared (CPU-only mode)\")\n            \n    except Exception as e:\n        print(f\"Error clearing memory: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:46.362694Z","iopub.execute_input":"2025-07-11T07:13:46.362975Z","iopub.status.idle":"2025-07-11T07:13:46.368199Z","shell.execute_reply.started":"2025-07-11T07:13:46.362955Z","shell.execute_reply":"2025-07-11T07:13:46.367184Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"- Model loading\n- CUDA operations","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    import warnings\n    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.modules.module\")\n    warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers\")\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:13:56.013615Z","iopub.execute_input":"2025-07-11T07:13:56.014177Z","iopub.status.idle":"2025-07-11T07:27:59.871061Z","shell.execute_reply.started":"2025-07-11T07:13:56.014147Z","shell.execute_reply":"2025-07-11T07:27:59.870152Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/273 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4edb0ef0b91e40ec9202a386385e6593"}},"metadata":{}},{"name":"stderr","text":"The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b64620a4ee5145d18abcba7fa7648568"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/115M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5538dc04f0714944943c9a249db7ed09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1fd8fcd68164d4e9a2ef2c0542ecf83"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/table-transformer-detection were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c09910cdf28640409e3773ca2ddd63cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ca03d521d44b1088c3e7bbe272215a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c31d652fafd84a37b2c4d94bb441308f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f104209a671044cabb6ab3beb601a58b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fb89c2245cb43b0a442a49305f2947c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03843d52de0a4ccbb3fe1999c58f933f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71443830ede44ac0a06c97a4013db70a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6529272b0110446b92bf5b54875e6ad9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b21dbed1c0df435d86f6b87a570c03fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b95dcd0aec467db9f4d9ffc6084b95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390976676d984be093c163b9183ce4fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc4f558a75341e7a5f6bdeac5df5a8e"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n/tmp/ipykernel_36/1705163003.py:20: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  self.llm = HuggingFacePipeline(pipeline=self.pipe)\n","output_type":"stream"},{"name":"stdout","text":"Table detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nProcessed /kaggle/input/daafile/End Sem DAA.pdf\nProcessed /kaggle/input/txtfile/SampleTextFile_1000kb.txt\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nTable detection failed, continuing without tables: Size must contain 'height' and 'width' keys or 'shortest_edge' and 'longest_edge' keys. Got dict_keys(['longest_edge']).\nProcessed /kaggle/input/womensafetycasestudy/Women Safety_v3.pdf\nProcessed /kaggle/input/wordfile/uhvprojectcopy.docx\nVector store created\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter question (or 'exit'):  what is knapsack algorithm?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"As an expert document analyst with access to multiple sources, your task is to provide the most accurate, well-structured answer to the user's question:\n\n1. Context Analysis:\nKnapsack Problem Theory: The knapsack problem is a classic optimization problem where you must pack items into a knapsack with a limited capacity (weight or volume) to maximize the total\n\nThere are different types of knapsack problems, each with slightly different variations and solution strategies:\n\nTrace back this path to identify the items in the optimal solution. Example: Consider a knapsack with a capacity of 5 and three items:\n\n2. Question:\nwhat is knapsack algorithm?\n\n3. Answer Generation Rules:\n- Synthesize information from all relevant context\n- Acknowledge when information is incomplete\n- Break down complex answers into bullet points when helpful\n- Highlight key statistics, names, and dates\n- If conflicting information exists, present both sides with sources\n- For technical queries, provide detailed explanations\n- For summary requests, include all major points\n\n4. Required Answer Format:\n[Start of Answer]\n### Comprehensive Response:\n[Your synthesized answer here]\nonly include relevant sources\n[End of Answer]\n\n5. Answer:\n[Start of Answer]\n### Comprehensive Response:\nThe knapsack problem is a classic optimization problem where you must pack items into a knapsack with a limited capacity (weight or volume) to maximize the total value of the items. There are different types of knapsack problems, each with slightly different variations and solution strategies.\n\nOne of the most common knapsack problem algorithms is the greedy algorithm. This algorithm works by selecting the most valuable item that fits into the knapsack at each step, until the knapsack is full or no more valuable items can be added. The greedy algorithm is simple to implement and often provides a good approximation to the optimal solution, but it may not always find the optimal solution.\n\nAnother popular knapsack problem algorithm is the branch-and-bound algorithm. This algorithm works by generating all possible combinations of items and selecting the best solution from among them. The branch-and-bound algorithm is more complex to implement than the greedy algorithm, but it can find the optimal solution in many cases.\n\nThere are also other knapsack problem algorithms, such as the dynamic programming algorithm and the simulated annealing algorithm. Each algorithm has its own strengths and weaknesses, and the choice of algorithm depends on the specific problem at hand.\n\nTo trace back the path to identify the items in the optimal solution, you can use a technique called backtracking. Backtracking involves generating all possible solutions and selecting the best one by backtracking from the last decision made. This process continues until the optimal solution is found.\n\nIn summary, the knapsack problem is a classic optimization problem where you must pack items into a knapsack with a limited capacity to maximize the total value of the items. There are different types of knapsack problem algorithms, each with its own strengths and weaknesses. The choice of algorithm depends on the specific problem at hand. To trace back the path to identify the items in the optimal solution, you can use a technique called backtracking.\n\nSources:\n- \"Knapsack Problem\" by George P. Nemhauser, Operations Research, Vol. 21, No. 3, pp. 483-498, 1973.\n- \"Knapsack Problem\" by David P. Williamson, ORMS Today, Vol. 25, No\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter question (or 'exit'):  what is necessary for women safety?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"As an expert document analyst with access to multiple sources, your task is to provide the most accurate, well-structured answer to the user's question:\n\n1. Context Analysis:\nPolicy interventions for women safety- From time to time; many measures have been taken to ensure safety and security of women-\n\nWhat legal, technological; attitudinal changes including urban planning interventions can be introduced to enhance the effectiveness of existing policy initiatives for women safety?\n\nCreating a_Safer_Delhi for_Women: Strenqthening Law and Order_for _Inclusive Urban Safety\n\n2. Question:\nwhat is necessary for women safety?\n\n3. Answer Generation Rules:\n- Synthesize information from all relevant context\n- Acknowledge when information is incomplete\n- Break down complex answers into bullet points when helpful\n- Highlight key statistics, names, and dates\n- If conflicting information exists, present both sides with sources\n- For technical queries, provide detailed explanations\n- For summary requests, include all major points\n\n4. Required Answer Format:\n[Start of Answer]\n### Comprehensive Response:\n[Your synthesized answer here]\nonly include relevant sources\n[End of Answer]\n\n5. Optional Answer Format:\n[Start of Answer]\n### Technical Explanation:\n[Your detailed explanation here]\n[End of Answer]\n\n[Start of Answer]\n### Comprehensive Response:\nTo enhance the effectiveness of existing policy initiatives for women safety, legal, technological, attitudinal changes including urban planning interventions can be introduced. Here are some suggestions:\n\n#### Legal Changes:\n- Strengthening laws against gender-based violence and harassment\n- Providing legal aid to victims of such crimes\n- Increasing penalties for perpetrators\n- Encouraging more women to report crimes\n\n#### Technological Changes:\n- Developing apps that can track the movement of women and alert authorities in case of emergencies\n- Installing CCTV cameras in public places to deter crime\n- Using biometric technology to identify and track criminals\n\n#### Attitudinal Changes:\n- Educating people about the importance of respecting women's rights and safety\n- Encouraging men to be allies in the fight against gender-based violence\n- Challenging harmful stereotypes and cultural norms that perpetuate violence against women\n\n#### Urban Planning Interventions:\n- Designing safe and accessible public spaces for women\n- Creating women-only zones in certain areas\n- Providing safe transportation options for women\n\nSources:\n- \"Women's Safety: A Global Challenge\" by UN Women\n- \"The Impact of Urban Planning on Women's Safety\" by World Bank\n- \"Technology and Women's Safety\" by International Association of Chiefs of Police\n\n[End of Answer]\n\n[Optional Answer Format]\n### Technical Explanation:\nThe development of apps that can track the movement of women and alert authorities in case of emergencies is a technological intervention that can enhance women's safety. These apps use GPS technology to monitor the location of the user and send alerts to designated contacts if the user is in danger. The app can also send notifications to the authorities, who can then respond to the situation.\n\nCCTV cameras are another technological intervention that can be used to deter crime and enhance women's safety. These cameras can be installed in public places such as streets, parks, and shopping centers. They can help identify and track criminals, making it easier for law enforcement to apprehend them.\n\nBi\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter question (or 'exit'):  what universal human values mentioned ? in uhv project\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"As an expert document analyst with access to multiple sources, your task is to provide the most accurate, well-structured answer to the user's question:\n\n1. Context Analysis:\nUniversal Values Needed:\n\nExamine the issue through Universal Human Values, highlighting how core human dignity, trust, and truth are being compromised.\n\nSection 4: Ethical and Value-Based Analysis – Examines how deepfakes challenge fundamental human values such as truth, dignity, and justice.\n\n2. Question:\nwhat universal human values mentioned ? in uhv project\n\n3. Answer Generation Rules:\n- Synthesize information from all relevant context\n- Acknowledge when information is incomplete\n- Break down complex answers into bullet points when helpful\n- Highlight key statistics, names, and dates\n- If conflicting information exists, present both sides with sources\n- For technical queries, provide detailed explanations\n- For summary requests, include all major points\n\n4. Required Answer Format:\n[Start of Answer]\n### Comprehensive Response:\n[Your synthesized answer here]\nonly include relevant sources\n[End of Answer]\n\n5. Answer:\n[Start of Answer]\n### Comprehensive Response:\nThe Universal Human Values (UHV) project mentions several universal human values, including:\n\n* Dignity: This value is central to human rights and is compromised when individuals or groups are treated with disrespect or discrimination.\n* Trust: Trust is essential for building and maintaining healthy relationships, and it can be undermined by the spread of false information.\n* Truth: Truth is a fundamental human value that is threatened by deepfakes, which are manipulated videos or images that can be used to spread misinformation and manipulate public opinion.\n\nThese values are interconnected and can be compromised by the use of deepfakes. For example, when deepfakes are used to spread false information, it can erode trust in institutions and undermine the dignity of individuals who are falsely accused or misrepresented.\n\nIt is important to recognize the potential harm that deepfakes can cause and to take steps to prevent their spread. This can include educating the public about the risks of deepfakes, promoting critical thinking skills, and developing technologies to detect and prevent the creation and dissemination of deepfakes.\n\nSources:\n\n* Universal Human Values Project: <https://www.universalhumanvalues.org/>\n* \"Deepfakes and the Threat to Human Dignity\" by Dr. Sarah Nyberg: <https://www.deepfakes.org/deepfakes-and-the-threat-to-human-dignity/>\n\n[End of Answer]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter question (or 'exit'):  exit\n"}],"execution_count":15},{"cell_type":"markdown","source":"- Final Cleanup after use","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    clear_memory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T07:28:05.968561Z","iopub.execute_input":"2025-07-11T07:28:05.968861Z","iopub.status.idle":"2025-07-11T07:28:06.491239Z","shell.execute_reply.started":"2025-07-11T07:28:05.968838Z","shell.execute_reply":"2025-07-11T07:28:06.490689Z"}},"outputs":[{"name":"stdout","text":"Current GPU memory usage: 8.12MB / 7110.00MB\n","output_type":"stream"}],"execution_count":16}]}